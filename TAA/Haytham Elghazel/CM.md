# <mark style="background: #BBFABBA6;">Apprentissage automatique</mark>

- # Contexte
	- ## Objectifs
		- Consiste à inférer des connaissances sur les données
		- Se base sur des échantillons d'apprentissage
		- Si présence d'une cible
			- ==> Apprentissage supervisé
		- Si absence d'une cible
			- ==> Apprentissage non supervisé
	- ## Données initiales
		- Des individus/instances/Objets --> n
		- Des variables/features/descripteurs --> p
		- Des labels
		- ==> ![[Pasted image 20241212183417.png]]
- # Apprentissage supervisé
	- ## Définition
		- Méthode d’apprentissage utilisée pour construire un **classiffieur** (ou modèle ou hypothèse), à partir d’une **base d’exemples étiquetés par des labels**, pour **prédire le label d’un nouvel individu** qui arrive.
	- ## Algorithmes
		- ### Réseaux bayésiens
		- ### Réseau de neurones
		- ### K-plus proches voisins
		- ### Arbres de décision
			- #### Définition & Fonctionnement
				- Processus récursif de division de l’espace des données en sous-régions de plus en plus **pures** en terme de classes.
				- Les tuples sont placés dans la classe associée à la sous-région qu’ils vérifient
				- Différentes approches en fonction de la façon dont l’arbre est construit
			- Décomposition d’un problème de classification en une suite de **tests** (**imbriqués**) portant sur **une variable (parallèle aux axes)** ou **une combinaison linéaire de plusieurs variables (oblique)**.
			- #### Exemple
				- On veut faire un decision tree répondant à l'objectif : **Déterminer si un client consultera son compte par Internet, en fonctions des données que l'on a sur lui**
				- On a un échantillon d'apprentissage : ![[Pasted image 20241212184621.png]]
					- On a 8 individus
					- On a 4 variables (avec différentes valeurs possibles):
						- M --> Moyenne du solde de comptes
						- A --> Age
						- R --> Résidence
						- E --> Niveau d’études
					- On a les labels associés :
						- Oui --> L'individu consulte son compte par Internet
						- Non --> L'individu ne consulte pas son compte par Internet
				- ##### Cinétique
					- ###### Racine de l'arbre
						- Pas de test à faire, nous avons déjà les labels
							- (3,5)
								- 3 Oui
								- 5 Non
					- ###### Premier test
						- On va privilégier les tests qui produisent des **feuilles pures** = Tout les individus sont dans une **même classe** ![[Pasted image 20241212185800.png]]
							- ==> Regarder/Tester la variable R --> Pas de feuilles pures --> Pas discriminatoire et donc pas très intéressant de regarder
							- ==> Regarder/Tester la variable A --> 2/3 des feuilles pures --> C'est plus intéressant (pour les branches jeunes et âgé)
						- Comment mathématiquement coder ça ?
							- Cf Méthodes
				- ##### Méthodes 
					- ###### Entropie
						- Définition
							- Il nous faudrait une méthode qui puisse repérer ces variables et tests intéressants
							- Ce serait donc une fonction qui serait :
								- Minimum (=0) lorsque le nœud est pur
								- Maximum lorsque les individus sont équi-répartis dans les classes
							- ==> **Entropie** = Mesure du désordre
								- ![[Pasted image 20241212191301.png]] 
									- $p$ --> Nombre totale d'individus classé
									- $k$ --> Nombre d'individus classé pour chaque classe
						- Exemple
							- ![[Pasted image 20241212192848.png]]
					- ###### L'indice de Gini
						- Définition
							- On peut adapter la formule de l'entropie pour obtenir **l'indice de Gini**, qui est plus rapide et moins coûteux à calculer
							- ![[Pasted image 20241212191437.png]]
							- Mesure la probabilité qu'une observation choisie au hasard soit mal classée si elle était attribuée à une classe au hasard
						- Interprétation
							- $Gini (p) = 0$ --> Pureté maximale = Toutes les données dans une seule classe
							- $Gini (p) = 0.5$ --> Pour un ensemble binaire, indique une grande incertitude = Les classes sont réparties équitablement
						- ==> On a des méthodes (Entropie et Gini) pour mesurer le désordre mais il faudrait une méthode pour savoir quel test choisir, quelle variables à tester
							- ==> Fonction de gain
					- ###### Fonction de Gain
						- Définition
							- Évaluer l'efficacité d'une division des données en fonction d'une caractéristique et mesure la réduction de l'incertitude (ou de l'impureté) après une division
							- ![[Pasted image 20241212204357.png]]
								- $p$ --> Position (avant la division)
								- $test$ -> Variable que l'on test
								- $P_{j}$ --> Fréquence totale d'individu/d'observation pour un nœud enfant donné de la variable à tester
								- $i(p)$ ou $i(p_{j})$ --> $Entropie(p)$ ou $Gini(p)$ = Entropie ou Gini à la position p (avant la division) = Impureté du nœud parent ($i(p)$), ou nœud enfant ($p_{j}$)
							- ==> Le test à choisir est celui qui possède le plus grand gain
						- Exemple
							- ![[Pasted image 20241212204721.png]]
							- De la même manière :
								- ($Gain(\in, M) =0.266$)
								- $Gain(\in, A) =0.454$
								- $Gain(\in, R) =0.016$
								- $Gain(\in, E) =0.348$
							- ==> Il faut mieux réaliser tester A (le plus grand gain)
				- ##### Algorithme
					- ![[Pasted image 20241212210523.png]]
					- Pseudocode
						- Input: Dataset (D), Liste des caractéristiques (Features), Critère d'impureté (Entropie ou Gini), Profondeur maximale (MaxDepth)
						- Procedure DecisionTree(D, Features, CurrentDepth)
							- Si tous les exemples dans D appartiennent à la même classe :
								- Retourner une feuille avec la classe dominante.
							- Si Features est vide OU CurrentDepth ≥ MaxDepth :
								- Retourner une feuille avec la classe dominante dans D.
							- Calculer l'impureté parentale (ex. Entropie ou Gini) pour D.
							- Pour chaque caractéristique f dans Features :
								- Diviser les données en sous-ensembles basés sur les valeurs possibles de f.
								- Calculer l'impureté pondérée des enfants après la division.
								- Calculer le Gain d'information pour f.
							- Sélectionner la caractéristique (BestFeature) qui donne le Gain d'information maximal.
							- Diviser D en sous-ensembles (Subsets) basés sur BestFeature.
							- Créer un nœud interne pour BestFeature.
							- Pour chaque sous-ensemble (Subset) obtenu :
								- Si Subset est vide :
									- Ajouter une feuille avec la classe dominante de D comme prédiction.
								- Sinon :
									- Ajouter un sous-nœud en appelant récursivement DecisionTree(Subset, Features - {BestFeature}, CurrentDepth + 1).
							- Retourner le nœud construit.
			- #### Évaluation
				- Sur un nouveau jeu de donnée étiqueté, différent du jeu de donnée d'entrainement, on utilise l'algorithme pour prédire les labels -> On réalise la table de confusion et on calcule des métrique :
					- L'accuracy
					- L'erreur
					- Le Rappel(Oui)
					- La Précision(Oui)
					- La F-mesure(Oui)
				- ![[Pasted image 20241212213205.png]]

---

# <mark style="background: #BBFABBA6;">Méthodes ensemblistes</mark>

- # Définition
	- Méthode qui combine les décisions individuelles de plusieurs hypothèses h1 , . . . , hT pour classer de nouveaux exemples.
		- Un classifieur peut se tromper, un comité de classifieur **indépendant** à moins de chance de se tromper, on a un consensus
	- Il faut cependant que :
		- Les hypothèses construites ont un taux de succès meilleur que l’aléatoire (erreur<0.5 dans le cas de deux classes équilibrées).
		- Les hypothèses présentent une certaine diversité.
- # Types
	- ## Hétérogènes
		- Ensemble d'hypothèse produite par :
			- **Des algorithmes différents ($L_{n}$) sur une même distribution ($D$) des exemples d'apprentissage ($A$)**
			- *Ou...*
			- **Un même algorithme mais avec des paramètres et/ou initialisation différentes**
	- ## Homogènes
		- ### Définition
			- Ensemble d'hypothèse produite par un **même algorithme ($L$)** mais avec **des distributions ($D_{t}$) différentes ( tirages aléatoires, pondérations différentes...) dans la base d'apprentissage**
			- Méthode générale et facilement applicable car basique
		- ### Stratégies
			- #### Boosting
				- ##### Définition
					- Utiliser une stratégie adaptative pour booster des performances, applicable à tout type d’algorithme (Réseau de neurones, CART, etc.)
					- Méthode générale pour convertir des règles de prédiction peu performantes en une règle de prédiction (très) performante
						- Étant donné un algorithme d’apprentissage L “faible” qui peut toujours retourner une hypothèse h de taux d’erreurs $\leq$ 0.5 - $\gamma$ (où $\gamma$ est l’amélioration de h par rapport à une décision aléatoire)
						- Un algorithme de boosting peut construire (de manière prouvée) une règle de décision (hypothèse) de taux d’erreur $\leq$ e
				- ##### Adaboost
					- ###### Définition
						- Adaptative Boosting
						- Algorithme itératif pour l’ajout des classifieurs
						- Variantes de la base d’apprentissage obtenues par des pondérations successives des mêmes exemples (calculées pour «se focaliser» sur les exemples «difficiles»)
						- **On augmente l’importance des exemples mal-classés lors de l’itération précédente**
						- ==> Combine plusieurs modèles faibles (**weak learners**) pour créer un modèle global plus performant (**strong learner**). L'objectif est de corriger les erreurs des modèles faibles successifs afin d'améliorer la précision globale.
					- ###### Exemple
						- Etape 0
							-  ![[Pasted image 20241212221750.png]] 
						- Etape 1
							-  ![[Pasted image 20241212221811.png]]
								- $\epsilon_{1}$ --> Erreur pondéré
								- $\alpha$ --> Performance du modèle 
							- Cinétique
								- Un modèle est construit --> Il classe correctement 70% des données et se trompe sur 30% --> Les erreurs reçoivent des poids plus élevés.
						- Etape 2
							- ![[Pasted image 20241212221906.png]]
							- Cinétique
								- Un nouveau modèle est construit en se concentrant sur les exemples mal classés du premier modèle --> Il corrige certaines erreurs du premier modèle
						- Etape 3
							- ![[Pasted image 20241212221927.png]]
						- Hypothèse finale
							- ![[Pasted image 20241212221956.png]]
							- Cinétique
								- Les 3 modèles sont combinés en tenant compte de leur importance respective ($\alpha_{t}$).
					- ###### Avantages
						-  Performance élevée sur des tâches de classification.
						- Pas de réglage complexe : Seul le nombre d'itérations TT doit être spécifié.
						- Interprétable : Les poids $\alpha_{t}$ ​ montrent l'importance des modèles faibles.
					- ###### Bilan adaboost
						- ==> Utilisé un algorithme de classification (L) qui intègre le poids des individus dans la phase d'apprentissage
							- ==> Par exemple : Arbre de décision, Réseaux de neurones, ...
						- ==> A chaque itération t un nouvel échantillon d’apprentissage est considéré en sélectionnant au hasard avec remise $m$ exemples suivants les poids
				- ##### Bilan Boosting
					- ==> La puissance du boosting vient du ré-échantillonnage adaptatif
					- ==> Réduit la variance
					- ==> Réduit le biais en obligeant l'algorithme à focaliser sur les cas difficiles → hypothèse combinée beaucoup plus flexible
					- ==> Convergence rapide
					- ==> Sensible au bruit : les apprenants de base classent mal les exemples bruités ⇒ poids augmentent ⇒ sur-ajustement au exemples bruités
			- #### Bagging
				- ##### Définition
					- Utiliser l’aléatoire pour améliorer les performances d’algorithmes de « faibles » performances. C’est applicable à différents algorithmes et RF est un aménagement spécifique à CART.
					- Bootstrap aggregation
					- Variantes de la base d’apprentissage obtenues par tirages aléatoires avec remise depuis la base initiale (sorte de «bootstrap»)
						- Un ensemble de données « bootstrap » est un ensemble de données obtenu en sélectionnant au hasard avec remise m observations parmi les m observations de l’ensemble d’entraînement.
						- Certaines observations sont dupliquées tandis que d’autres sont absentes; ce qui introduit une part d’aléatoire.
					- L’intérêt de telle méthode est de répéter la procédure et d’utiliser chaque ensemble de données pour construire un modèle. Nous disposons alors de différentes réalisations de la statistique estimée (ou du modèle).
				- ###### Principe
					- Génération de k échantillons « bootstrap » par tirage avec remise dans l’ensemble d’apprentissage A= {(x1,y1), … ,(xm,ym)}.
					- Pour chaque échantillon, apprentissage d’un classifieur en utilisant le même algorithme d’apprentissage
					- La prédiction finale pour un nouvel exemple est obtenue par vote (simple) des classifieurs
				- ###### Bilan Bagging
					- ==> But
						- Atténuer l'instabilité inhérente à certaines méthode de discrimination
							- Si un changement mineur dans les données provoque un changement assez important de modèle = Méthode de discrimination instable 
					- ==> Utile et efficace si algorithme de base utilisé est instable car différences entre variantes de base --> classifieurs élémentaires très différents
					- ==> Évite l’overfitting (sur-apprentissage), car on a la «moyenne» des classifieurs construits avec différentes réalisations aléatoires des mêmes données.
					- ==> Il est souvent dit que le bagging fonctionne en réduisant la variance en laissant le biais inchangé
			- #### Random Forest
				- ##### Principe
					- Est ce qu’à partir d’un ensemble de faible classifieurs (arbres de décision) ont peut créer un classifieur plus performant?
					- L’union fait-elle la force?
						- La réponse est oui à condition que les arbres sont complémentaires.
					- Le résultat sera donc autant plus intéressant que les arbres sont indépendants et le plus efficaces possible.
					- On va construire un grand nombre d’arbres de décision différents pour un même problème: une forêt (forest).
					- Pour construire une forêt on injecte de l’aléatoire: 
						- On rajoute de l’aléatoire avant ou pendant la construction d’un arbre (Algorithme CART); on construit plusieurs arbres “randomisés”
						- On agrège l’ensemble des arbres obtenus:
							- Pour classer un individu on prend la décision finale par un vote majoritaire
					- Pour rajouter l’aléatoire, RF combine la sélection aléatoire d'instances avec la sélection aléatoire de variables.
						- On lance la construction de l’arbre sur un sous échantillon tiré aléatoirement : Breiman propose d’utiliser le bagging
						- On tire à chaque nœud de l’arbre **mtry** variables uniformément et on cherche la “meilleure” coupure uniquement parmi ces variables-ci.
						- Les arbres de décision sont complets : construits automatiquement sans pre- ou post-élagage.
				- ##### Algorithme
					- ![[Pasted image 20241212230942.png]]
				- ##### Avantages
					- Comme on tire aléatoirement les observations, une partie des observations non tirées (appelées OOB = Out Of Bag) serviront à 
						- Évaluer en interne la forêt
						- Estimer l'importance des variables pour la selections des variables
				- ##### Évaluation
					- Estimation de l'erreur en généralisation
						- ![[Pasted image 20241212231518.png]]
				- ##### Optimisation
					- ![[Pasted image 20241212231553.png]]
					- Le nombre optimal de variables dépend du nombre d'arbre dans la forêt mais globalement le plus optimal est 6 classes de variable
				- ##### Applications
					- ###### Clustering
						- ![[Pasted image 20241212231929.png]]
					- ###### Sélection de variables
						- ![[Pasted image 20241212231946.png]]
					- ###### Gestion des valeurs manquantes
						- ![[Pasted image 20241212232009.png]]
				- ##### Bilan Random Forest
					- ==> Facile en utiliser
					- ==> Sélection d'un sous-ensembles des observations
						- ==> Gain de temps et de calcul
						- ==> Grande diversité des modèles
					- ==> Agrégation des valeurs ou classes prédites pour chaque modèles donne un classifieur robuste et précis

---

# <mark style="background: #BBFABBA6;">Apprentissage multi-label</mark>

- # Introduction
	- ## Définition
		- C'est lorsque notre base d'apprentissage possèdent :
			- Comme d'habitude :
				- Des observations en lignes
				- Des variables/features en colonnes
			- MAIS...
				- **Plusieurs labels/étiquettes** pour chaque individus
	- ## Exemple
		- ![[Pasted image 20241213085417.png]]
	- ## Domaines d'application
		- Catégorisation de texte
		- Classification des fonctions génétiques
		- Annotation sémantique des images, vidéos
- # Apprentissage multi-label
	- ## Représentation & Fonction de classification
		- ![[Pasted image 20241213085728.png]]
	- ## Métriques d'évaluation
		- ### Hamming Loss
			- #### Définition
				- Mesure le taux d'erreurs par étiquette, en prenant en compte les FP (étiquettes incorrectement prédites) et les FN (étiquettes manquées)
			- #### Calcul
				- ![[Pasted image 20241213085955.png]]
					- $N$ --> Nombre d'observations
					- $Q$ --> Nombre d'étiquettes/labels
					- $y_{ij}$ --> Étiquette réelle de l'individu $i$, et étiquette $j$
					- $ŷ_{ij}$ --> Étiquette prédite de l'individu $i$, et étiquette $j$
			- #### Exemple
				- ![[Pasted image 20241213095051.png]]
				- ![[Pasted image 20241213095156.png]]
		- ### 0/1 Loss (Subset Accuracy)
			- #### Définition
				- Mesure si l'ensemble des étiquettes prédites pour un exemple/observation/individu correspond exactement à l'ensemble des étiquettes réelles. 
				- Plus stricte que la Hamming Loss
			- #### Calcul
				- ![[Pasted image 20241213090442.png]]
					- $Y_{i}$ --> Ensemble des étiquettes réelles pour l'individu/observation $i$
					- $Ŷ_{i}$ --> Ensemble des étiquettes prédites pour l'individu/observation $i$
			- #### Exemple
				- ![[Pasted image 20241213095106.png]]
				- ![[Pasted image 20241213095230.png]]
		- ### F1-Score
			- #### Définition
				- Évaluer la performance d'un modèle. Il existe deux variantes principales pour calculer le F1-Score dans ce contexte Multi label : Micro F1 et Macro F1.
				- Permettent d'obtenir des perspectives différentes sur les performances d'un modèle, en particulier lorsque le jeu de données est déséquilibré
			- #### Types
				- ##### Micro-F1
					- ###### Définition
						- Elle prend en compte toutes les étiquettes ensemble comme si elles appartenaient à une seule classe. 
						- Le F1-Score est calculé en agrégeant les vrais positifs (TP), faux positifs (FP) et faux négatifs (FN) sur toutes les étiquettes avant d'effectuer le calcul. 
						- Cette métrique est particulièrement utile lorsque vous voulez accorder plus de poids aux classes fréquentes.
					- ###### Calcul
						- ![[Pasted image 20241213195702.png]]
							- ![[Pasted image 20241213195732.png]]
				- ##### Macro-F1
					- ###### Définition
						- Elle traite chaque étiquette indépendamment. 
						- Elle calcule le F1-Score pour chaque étiquette individuellement, puis prend la moyenne arithmétique de ces scores. 
						- Cette approche donne un poids égal à chaque étiquette, quel que soit le nombre d'occurrences de cette étiquette dans le jeu de données.
					- ###### Calcul
						- ![[Pasted image 20241213200113.png]]
	- ## Algorithmes
		- ### Méthodes d'adaptation
			- #### Définition
				- Méthodes adaptant les algorithmes de classification mono-label existants vers des algorithmes multi-labels, comme par exemple :
					- MLkNN (k-plus proches voisins)
					- PCT (Predictive Clustering Tree)
		- ### Méthodes de transformation
			- #### Définition
				- Méthodes adaptant le problème multi-label en un ou plusieurs problèmes mono-label gérables avec des classifieurs traditionnels
				- La prédiction finale du label se fera généralement par vote du label majoritairement prédit par tous les classifieurs
			- #### Types
				- ##### Méthode BR (= Binary Relevance)
					- On transforme notre base d'apprentissage multi-label en plusieurs bases d'apprentissage mono-label --> Même features pour les individus mais à chaque fois un seul label et à chaque fois un label différent
					- ![[Pasted image 20241213203133.png]]
					- ###### Avantages
						- Très simple car classifieurs standards
						- Facilement scalable quand grand nombre de label
					- ###### Inconvénients
						- Ne prend pas en compte les dépendances et corrélations inter-labels
						- Modèles déséquilibré si certains labels sont rares
				- ##### Méthode Pair-wise
					- Ici on crée plusieurs bases d'apprentissage avec les même features (comme avant) mais cette fois on créé un nouveau label reflétant l'interaction entre chaque paire de label possible
						- Pour un nouveau label $\lambda'_{i,j}$ :
							- Si $\lambda_{i} = 1 \Rightarrow \lambda'_{i,j} = 1$
							- Si $\lambda_{j} = 1 \Rightarrow \lambda'_{i,j} = 0$
					- On créé autant de nouveau label (et donc de base d'entrainement) qu'il y a de paire de label initial possible
						- Si on a Q labels initials, on aura $\frac{Q*(Q-1)}{2}$ nouvelles bases d'entrainement mono-label avec les nouveaux labels 
					- ![[Pasted image 20241213210339.png]]
					- ###### Avantages
						- Simple car classification binaire
						- Précision élevée car chaque classifieur traite un problème binaire simple
					- ###### Inconvénients
						- Complexité car le nombre de classifieur augmente quadratiquement
						- Parfois il y a des conflits de vote entre classifieurs
				- ##### Méthode LP (= Label Power-set)
					- Cette méthode va transformer les labels en créant un nouveau type de label pour chaque combinaison unique d'ancien labels possibles
						- Il y a aura donc autant de classifieur qu'il y a de combinaison possible de label
					- ![[Pasted image 20241213211454.png]]
					- ###### Avantages
						- Capture des dépendances inter-labels
					- ###### Inconvénients
						- Explosion combinatoire avec $2^L$ combinaisons possibles (L = Nombre label)
						- Sensibilité aux données/combinaison de label rare
		- ### Méthodes ensemblistes pures
			- #### Random Forest Predictive Clustering Tree (RFPCT)
				- ##### Concept
					- RFPCT est une méthode dérivée des arbres de décision et des forêts aléatoires, spécifiquement adaptée pour les problèmes multi-étiquettes. Contrairement aux méthodes classiques, elle utilise des arbres de clustering prédictif (PCTs) pour construire un modèle qui peut prédire plusieurs labels simultanément, en capturant les relations entre les étiquettes.
				- ##### Étapes principales :
					- ###### Construction des PCTs :
						- Chaque arbre est construit en considérant un critère d'impureté qui évalue non seulement la qualité de la séparation pour une étiquette, mais également pour toutes les étiquettes combinées.
						- Les feuilles contiennent des distributions ou moyennes des labels multi-étiquettes.
					- ###### Ensemble de forêts :
						- Plusieurs arbres PCT sont entraînés sur des échantillons aléatoires (avec remplacement) des données.
						- Chaque arbre prédit un ensemble d'étiquettes, et les prédictions sont agrégées (par exemple, par vote majoritaire).
					- ##### Capture des dépendances entre labels :
						- Contrairement à des forêts aléatoires standard, les RFPCTs tiennent compte des dépendances entre les étiquettes.
				- ##### Avantages :
					- Capture des corrélations entre les étiquettes.
					- Utilisation efficace des relations hiérarchiques ou des dépendances dans les données.
				- ##### Limites :
					- Peut être coûteux en termes de calcul pour un grand nombre d'étiquettes ou d'arbres.
			- #### Random k-label sets (RakEL)
				- ##### Concept
					- RakEL transforme un problème de classification multi-étiquette en un ensemble de problèmes de classification multi-classes. Il sélectionne aléatoirement des sous-ensembles de labels (appelés k-label sets) et entraîne des classificateurs indépendants sur ces sous-ensembles
					- ![[Pasted image 20241213213947.png]]
				- ##### Étapes principales :
					- ###### Sélection des k-label sets :
						- m sous-ensembles aléatoires de k étiquettes sont sélectionnés (k est un hyperparamètre).
						- Par exemple, si k=3 et qu'il y a 5 étiquettes (L=5), chaque sous-ensemble pourrait contenir une combinaison comme {A,B,C}.
					- ###### Transformation des étiquettes :
						- Pour chaque k label set, toutes les combinaisons possibles des k étiquettes sont traitées comme des classes uniques (similaire à Label Power-set).
					- ###### Entraînement des modèles :
						- m modèles sont entraînés sur les différents k-label sets.
					- ###### Prédiction :
						- Lors de la prédiction, les modèles pour chaque k-label set sont utilisés, et les résultats sont combinés (par exemple, par vote majoritaire).
				- ##### Avantages :
					- Réduit la complexité combinatoire de la méthode Label Power-set (car on travaille sur des sous-ensembles aléatoires de labels).
					- Améliore la capture des dépendances entre labels par rapport à des méthodes simples comme Binary Relevance.
				- ##### Limites :
					- La performance dépend du choix de k et du nombre de sous-ensembles m
					- Peut être coûteux pour un très grand nombre de labels ou si k est trop grand.
			- #### Ensemble Classifier Chain (ECC)
				- ##### Concept
					- ECC est une méthode d'ensemble basée sur la technique des Classifier Chains (CC). Dans la méthode CC, les étiquettes sont prédites séquentiellement, et chaque prédiction est utilisée comme caractéristique pour les prédictions suivantes. ECC étend cette idée en créant un ensemble de chaînes de classificateurs, chacune avec un ordre aléatoire des étiquettes.
				- ##### Étapes principales :
					- ###### Construction des chaînes :
						- Plusieurs chaînes (M) de classificateurs sont créées, où chaque chaîne prédit les labels séquentiellement.
						- Pour chaque chaîne, un ordre aléatoire des labels est utilisé.
					- ###### Entraînement des chaînes :
						- Chaque chaîne est entraînée sur les données d'entraînement, où les étiquettes précédentes dans la chaîne sont utilisées comme caractéristiques supplémentaires.
					- ###### Prédiction :
						- Lors de la prédiction, les M chaînes effectuent des prédictions indépendantes. Les prédictions finales sont agrégées, par exemple, en prenant une moyenne ou un vote majoritaire.
				- ##### Avantages :
					- Capture explicitement les dépendances entre les labels, en particulier celles qui sont ordonnées.
					- Robuste et flexible, car chaque chaîne utilise un ordre aléatoire des labels.
				- ##### Limites :
					- L'ordre des labels peut influencer les performances.
					- Peut être coûteux si le nombre de chaînes (M) est trop élevé ou si le nombre de labels est grand.
	- ==> ![[Pasted image 20241213220231.png]]

---

# <mark style="background: #BBFABBA6;">Détection d'anomalies</mark>

- # Introduction
	- ## Objectifs
		- Identifier les instances ayant un comportement non conforme
		- Supprimer ou modifier les observations atypiques à un modèle sans justification serait totalement contraire à l’éthique.
		- L’objectif est avant tout de les identifier car ce sont celles, les plus susceptibles d’être la conséquence d’une erreur (à confirmer) de mesure, de libellé, ou encore une anomalie, défaillance ou tentative de fraude, d’intrusion, selon le contexte.
	- ## Approches
		- ### Détection d'outliers
			- Les données d’apprentissage contiennent des outliers et qui sont des observations qui se trouvent loin des autres.
			- Il s’agit d’apprendre à détecter les anomalies dans le jeu de données initial en cherchant des régions denses (où les données sont le plus concentrées) tout en ignorant les anomalies.
		- ### Détection de nouveauté
			- Ici le jeu de donnée pas pollué par les anomalies
			- Il s'agit de détecter des anomalies dans les données futures non déjà observées ==> Les outliers sont appelés nouveautés
- # Méthodes
	- ## Non supervisées
		- ### Généralités
			- Pas de labels fournis
			- Base d'apprentissage = Données normales + anomalies
			- Les anomalies sont très rares
		- ### Types
			- #### Approches basées sur le voisinages
				- ##### Définition
					- L’anomalie ou l’isolement d’une observation est apprécié par la proximité des points de son voisinage
				- ##### Local Outlier Factor
					- ###### Définition
						- Compare la densité locale des observations. S’il existe une différence entre le point observé et ses voisins, le point est considéré comme une anomalie. 
						- Cette méthode est basée sur les k plus proches voisins : la densité locale d’une observation est évaluée en considérant les k plus proche observations de son voisinage.
						- Utilisée pour la détection de nouveauté ou d'outliers
						- Méthode très puissante
					- ###### Calcul
						- $LOF(x)$
							- Moyenne du rapport $f_k(y)/f_k(x)$ pour tous les $y$ dans $N_k(x)$
							- Mesure l'écart local d'un point par rapport à ses k voisins les plus proches
								- $LOF(x) \sim 1$ --> Observation comparable à ses voisins
								- $LOF(x) < 1$ --> Observation dans une région dense
									- Dans les 2 cas ==> Observation $\ne$ Outlier
								- $LOF(x) \gg 1$ --> Observation $=$ Outlier
					- ###### Paramètres
						- $D_k(x)$
							- Distance d'un point x par rapport à son $k^{e}$ plus proche voisin 
						- $N_k(x)$
							- L'ensemble des k plus proche voisin d'un point x
						- $R_k(x,y)$
							- Distance d’accessibilité de x par rapport à y comme étant le $max(d(x,y) ; D_k(y))$
						- $AR_k(x)$
							- Distance d'accessibilité moyenne de x comme étant égale à la moyenne des distances d'accessibilité de x avec tous les points de son voisinage ($N_k(x)$)
						- $f_k(x)$
							- Densité d'accessibilité locale = Inverse de $AR_k(x)$
								- Une instance/observation normale est sensée avoir une densité locale similaires à ses voisins
								- Alors q'une instance anormale est sensée avoir une beaucoup plus petite densité locale 
					- ###### Exemple
						- ![[Pasted image 20241213235659.png]]
						- ![[Pasted image 20241213235757.png]]
				- ##### One class SVM
					- Séparer toutes les observations, de l’origine, dans l’espace de représentation en maximisant la marge, à savoir la distance entre l’hyperplan et l’origine
					- Pour la détection de nouveauté
				- ##### Isolation Forest
					- ###### Principe
						- Pour la détection d'outliers
						- Les anomalies sont rares et différentes ==> Susceptibles au mécanismes d'isolation
						- Construction d'ensemble d'arbres complement aléatoires ==> Isolation tree
						- Chaque arbres est construit sur échantillon aléatoire des instances
						- Divisions opéré dans chaque nœud via un filtrage aléatoire d'une variable et... :
							- Si variable quantitative :
								- Un seuil aléatoire
							- Si variables qualitative :
								- Une répartition aléatoire des modalités en 2 groupes
							- La construction de l'arbre jusqu'à obtention d'1 observation/individu par feuille
					- ###### Score
						- Score de l’isolement ou de l’anomalie d’une observation est obtenue par **la longueur du chemin atteignant cette observation**
						- Plus celui-ci est court, plus l’observation est considérée isolée ou atypique
					- ###### Exemple
						- ![[Pasted image 20241214002633.png]]
						- ![[Pasted image 20241214002659.png]]
	- ## Supervisées
		- ### Généralités
			- Labels à la fois pour les instances normales et anomalies
			- Anomalies appartiennent à la classe rare
			- Données déséquilibrées
			- Adaptation des approches supervisées existantes
				- Under-sampling / Oversampling / Balancing
					- (Bibliothèque `imblearn`)
		- ### Types
			- #### Random Under-sampling et Random Oversampling
				- ##### Under-sampling
					- ###### Définition
						- Sous échantillonnage
						- On diminue le nombre d'individus pour que les effectifs soient égaux
						- ![[Pasted image 20241214003625.png]]
					- ###### Inconvénients
						- Le classifieur risque d'apprendre dans un espace qui ne reflète pas la réalité 
							- ==> Il faut donc corriger les probabilités
					- ###### Exemple
						- Tomek Links
							- ![[Pasted image 20241214004114.png]]
				- ##### Balancing
					- ###### Définition
						- Pondération des classes
					- On va utiliser ici un LogLoss pondéré pour calculer l'erreur de notre classifieur ==> On la veut à 0 ou proche
				- ##### Oversampling
					- ###### Définition
						- Sur échantillonnage
						- On va dupliquer aléatoirement certains individus
						- ![[Pasted image 20241214003856.png]]
					- ###### Inconvénients
						- Le classifieur risque d'apprendre dans un espace qui ne reflète pas la réalité =
							- => Il faut corriger les probabilités
					- ###### Exemple
						- SMOTE (Synthetic Minority Oversampling Technique)
							- ![[Pasted image 20241214004324.png]]
							- Étapes
								- 1. Sélectionner aléatoirement une observation minoritaire “initiale”.
								- 2. Identifier ses k plus proches voisins parmi les observations minoritaires (où k est un paramètre défini par l’utilisateur)
								- 3. Choisir aléatoirement l’un des k plus proches voisins.
								- 4. Générer aléatoirement un coefficient ɑ.
								- 5. Créer un nouvel individu entre l’observation initiale et le plus proche voisin choisi, selon la valeur du coefficient ɑ. Par exemple, si ɑ=0.5, le nouvel individu sera positionné à mi-chemin entre l’observation initiale et le plus proche voisin choisi.
- # Évaluations
	- Accuracy déconseillé
	- Si on est intéressé par **la classe en sortie**
		- Si on veut les **classes + et -**
			- ==> **Balanced accuracy**
		- Si on est intéressé par la **classe + uniquement**
			- ==> **F 1-score**
	- Si on est intéressé par **les probabilités des classes en sortie**
		- Si on veut les **classes + et -**
			- ==> **AUC-ROC**
		- Si on est intéressé par la **classe + uniquement**
			- ==> **AUC-PR (Average Precision Score)**
				- Calcul de l'aire sous la courbe formée par les points de coordonnées (Rappel+, Précision+) en fonction du seuil (precision_recall_curve)
				- ![[Pasted image 20241214005450.png]]
	- ==> Ne pas évaluer les modèles sur un échantillon équilibré
	- ==> Les anomalies sont souvent complètement nouvelle ==> Le modèle ne pourra pas détecter les nouvelles anomalies sur lesquelles il n'a pas été entraîné

---

# <mark style="background: #BBFABBA6;">Natural Language Processing</mark>

- # Text Mining
	- ## Introduction & Contexte
		- ### Définition
			- Processus d'extraction non triviale d'informations utiles inconnues a priori à partir de grands volumes de textes
		- ### Spécificité
			- Les données sont sous une forme qui n’est pas directement exploitable par les méthodes classiques de Machine Learning
		- ### Objectifs
			- #### Identification de thèmes
				- Topic Modeling = Regroupement de (parties de) textes en thèmes inconnus a priori
			- #### Affectation de textes (ou partie) à des catégories
				- Dans des classes prédéfinies
			- #### Recherche de "variables" explicatives pertinentes
				- Utilisables ensuite conjointement avec d’autres variables (quantitatives, nominales)
			- #### Extraction d'information
				- Mise en correspondance des textes avec des « schémas » plus directement exploitables par des méthodes classiques de ML
	- ## Applications
		- Gestion de la relation client
			- Détermination de catégories de clients à partir de leurs échanges avec le service client, redirection des courriels mal adressés
		- Identification de l’objet des retours négatifs fréquents, détermination des causes majeures de l’attrition de clientèle
		- Détermination de l’image d’une famille de produits
		- Détermination des attentes majeures dans l’évolution des produits
		- Identification de tendances à partir de messages postés sur des médias sociaux :  Produits ou familles de produits recherchés, caractéristiques recherchées pour des produits d’une certaine famille
		- Analyse de comptes rendus médicaux
		- Génération/Résumé de textes
		- Traduction de textes
	- ## Préparation des données
		- ### Pré-traitement des données textuelles
			- Uniformisation du codage, élimination éventuelle de certains caractères spéciaux (sauts de lignes, symboles, etc. suivant l’objectif), «traduction» de langage SMS...
		- ### Extraction d'informations
			- Suppression des "mot ignorés" (stop words)
		- ### Extraction d'entités primaires
			- Mots, éventuellement composés (« chauve-souris »), locutions nominales (« chemin de fer »), verbales (« arrondir les angles »)...
		- ### Étiquetage grammaticale
			- Caractérisation grammaticale de chaque composante du texte par une catégorie lexicale (ex. nom commun, nom propre, verbe, adverbe...) et une fonction (ex. sujet, complément d’objet direct...)
		- ### Extraction d'entités nommées
			- Noms de personnes, de lieux (« Mont Blanc »), d’organisations, dates... qui jouent souvent un rôle important dans les opérations d’analyse de textes.
		- ### Lemmatisation ou Racinisation
			- Remplacer chaque mot (par ex. « pensons ») par sa forme canonique (« penser ») ou par sa racine (« pense ») ; peuvent engendrer des confusions (par ex. « organ » pour « organe » comme pour « organisation »)
			- Cette étape est utile car elle permet de traiter comme un mot unique les différentes variantes issues d’une même forme canonique ou racine
			- ==> Racinisation (Stemming) suffisante pour l’anglais
			- ==> Lemmatisation (lemmatization) mieux adaptée au français
		- ### Représentation vectorielle des textes
			- Pondération tf-idf, décomposition en valeurs singulières (SVD, LSA), analyse sémantique explicite (ESA), Word Embedding (plongement lexical) comme Word2vec, Bert, GPT, etc.
		- ### Développement de modèles
			- Sur la base du contenu textuel seul ou en ajoutant des variables quantitatives et nominales
		- ### Utilisation des modèles
			- Modèles développés, évaluation des résultats et interprétation
	- ## Challenges
		- ### Résolution référentielle
			- Cherche à identifier l’entité, explicitement présente ailleurs dans le texte, par ex., à qui fait référence Il dans « Barack Obama est le 44e président des États-Unis. Il est né le 4 août 1961 à Honolulu »
		- ### Analyse syntaxique (générale ou spécifique)
			- De la négation (→ distinction entre affirmation et négation), « quantification » des adverbes (ex. « très abouti / plus ou moins abouti / peu abouti »)
- # Représentation vectorielle des textes
	- ## Objectifs
		- Pouvoir manipuler des données textuelles avec les nombreux outils disponibles pour les espaces vectoriels
	- ## Prérequis
		- Au préalable, possible suppression des « mots ignorés » (stop words) : prépositions, conjonctions, articles, verbes auxiliaires...
			- L’ensemble des mots à ignorer peut dépendre de l’objectif de l’analyse !
			- Doit être appliquée seulement après l’extraction de locutions (ex. « chemin de fer »)
	- ## Définition
		- Modèle vectoriel de texte
			- Affecter une dimension de l’espace à chaque terme (lemme, entité nommée...) trouvé dans la base de documents → chaque texte est représenté par un vecteur de grande dimension, (très) clairsemé.
	- ## Exemple
		- ![[Pasted image 20241214020441.png]]
	- ## Représentations
		- ### TF-IDF
		- ### Test du $\chi²$
		- ### LSA (Latent Semantic Analysis)
	- 
	- 
	- Elle prend les mot qui apparaisse le plus dans me texte mais ne prend pas en compte le contexte la grammaire et syntaxe ==> On perds beaucoup d'info
	- Comparaison des vecteurs avec la distance cosinus :
		- Le norme du vecteur étant proportionnelle à la longueur du texte
	- On utilise parfois la similarité cosinus
	- .......
	- Évolutions de la représentation vectorielle de base
		- Pondération des termes : TF-IDF
			- Pondération les termes selon leur importance déterminé dans le texte
			- On utilise le TF (Term Frequency) dans le document
			- On multiplie le TD par IDF (Inverse Document Frequency) 
				- C'est l'importance d'un terme pour tous les documents ..........
				- Concept du LSA (=Latent Semantic Analysis)
					- ........
		- Sélection des termes : 
		- 
